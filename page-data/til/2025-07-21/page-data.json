{"componentChunkName":"component---src-pages-markdown-remark-frontmatter-slug-tsx","path":"/til/2025-07-21/","result":{"data":{"markdownRemark":{"html":"<h2><strong>TIL 21</strong></h2>\n<ul>\n<li>1년 만에 처음으로 검색 잡음,</li>\n<li>검색 상당히 흥미로우면서 진입 장벽이 존재하는듯.</li>\n<li>잘하려면 내부 로직을 더 잘 알아야하는 건 맞다고 생각함. 알고리즘적인 성격이 강해서.</li>\n</ul>\n<p>디써클 연구실 검색 기능 내가 임시 개편을 맡았는데, 일단 2시간 정도 토크나이저에 대해 리서치하고 바로 적용했다. 아래는 논리적 생각의 흐름이다.</p>\n<ul>\n<li>nori는 사전으로 tokenizing을 하는데 우리가 당장 전문용어 사전을 만들 수는 없는 노릇이니 패스.</li>\n<li>임베딩은 사전 없이도 의미론적 추론이 가능하지만 당장 시간이 없고 다다음 달즘에 다시 만들기로했으니 패스.</li>\n<li>default tokenizer은 띄어쓰기 단위인데 우리나라 말이랑 안맞아서 패스. (디지털 트윈, 디지털트윈 이 두 가지가 다르게 잡혀서 매우 안좋았음)</li>\n<li>ngram이 모든 tokenizer 중에서 제일 빠르고 좋게 쓸 수 있었음. 우리 회사의 경우에는 전문 용어가 많은데 전문 용어를 사전 없이 커버하려면 사실상 ngram이 가장 좋은 단기 해결책이었음.</li>\n</ul>\n<p>그리하여 ngram으로 min 2 max 5로 적용을 했음. 검색 품질이 대폭 향상되었고 회사 동료분들이 모두 만족해하셨음. (거의 시간을 하루만 쓰고 엄청 좋아졌으니)</p>\n<h2><strong>TIL 22</strong></h2>\n<ul>\n<li>저번주 bp 못받은게 여러 이유가 있겠지만 내가 크게 잘못한 점을 찾아보자면 일단 정책 문서가 꼼꼼하지 못했고, 정책 문서를 분석한 문서가 아예 없었다. 정책 문서를 분석한 문서가 가장 중요한 문서중 하나인데, 그게 아예 빠져있었음.</li>\n</ul>\n<h2><strong>TIL 30</strong></h2>\n<ul>\n<li>충격적이게도 3주차 항해 과제에서 fail 받음. 만회하기 위해 여러 개선책 강구중.</li>\n<li>다낭 여행와서 계속 과제 + 회사 업무중. 비행기에서 생각해낸 usecase + tiered architecture 구현해봄.</li>\n<li>배탈나서 오히려 호텔에 오래있어서 개발 계속 할 수 있었음.</li>\n<li>항해에서 배웠던 것들 적용해서 엄청나게 활용하고 있음. - 회사 tech spec 문서, 기능/비기능적 요구사항 분석 문서, 시퀀스 다이어그램 등 모두 내가 공부하고 고민했던 것들을 회사 문서에 다 녹여낼 수 있었음. - 이번 기업 발굴 SaaS 만들면서 만든 문서들임.</li>\n</ul>","frontmatter":{"date":"July 21, 2025","slug":"/til/2025-07-21","title":"2025 07 21","subtitle":"Logging what I learned daily"}}},"pageContext":{"id":"a91d1f3a-cb77-52e4-95c9-5634b78ba4de","frontmatter__slug":"/til/2025-07-21","__params":{"frontmatter__slug":"til"}}},"staticQueryHashes":["1865044719","2228436175","326441978"],"slicesMap":{}}